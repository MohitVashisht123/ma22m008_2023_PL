{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42ZKHFqO7SRg",
        "outputId": "41a4da1d-fc00-40dd-b4b4-93737a61b6b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                00006  1998  about  all  and  aside  ballots  became  by  \\\n",
            "Lincoln1865         0     0      0    1    0      0        0       0   0   \n",
            "TrumpMay26          0     0      0    0    0      0        1       0   0   \n",
            "Wikipedia           0     1      0    0    0      0        0       1   0   \n",
            "FortuneMay26        1     0      1    0    0      0        0       0   0   \n",
            "TheHillApr07        0     0      0    0    0      0        0       0   1   \n",
            "KingJamesBible      0     0      0    2    1      1        0       0   0   \n",
            "\n",
            "                charity  ...  total  toward  trump  two  us  voted  way  \\\n",
            "Lincoln1865           1  ...      0       1      0    0   0      0    0   \n",
            "TrumpMay26            0  ...      0       0      0    0   0      0    1   \n",
            "Wikipedia             0  ...      0       0      0    0   1      0    0   \n",
            "FortuneMay26          0  ...      1       0      0    1   0      0    0   \n",
            "TheHillApr07          0  ...      0       0      1    0   0      1    0   \n",
            "KingJamesBible        0  ...      0       0      0    0   0      0    0   \n",
            "\n",
            "                wherefore  with  zero  \n",
            "Lincoln1865             0     2     0  \n",
            "TrumpMay26              0     0     1  \n",
            "Wikipedia               0     0     0  \n",
            "FortuneMay26            0     0     0  \n",
            "TheHillApr07            0     0     0  \n",
            "KingJamesBible          1     0     0  \n",
            "\n",
            "[6 rows x 41 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "c = {\n",
        "    'Lincoln1865': 'With malice toward none, with charity for all ...',\n",
        "    'TrumpMay26': 'There is NO WAY (ZERO!) that Mail-In Ballots ...',\n",
        "    'Wikipedia': 'In 1998, Oregon became the first state in the US ...',\n",
        "    'FortuneMay26': 'Over the last two decades, about 0.00006% of total ...',\n",
        "    'TheHillApr07': 'Trump voted by mail in the Florida primary.',\n",
        "    'KingJamesBible': 'Wherefore laying aside all malice, and all guile, ...',\n",
        "}\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(c.values())\n",
        "matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=c.keys())\n",
        "\n",
        "print(matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh6bRlUp7W77",
        "outputId": "8f67c237-359e-44de-8ae6-89cd5b041247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def spacy_tokenizer(text):\n",
        "    tokens = nlp(text)\n",
        "    return [token.lemma_ for token in tokens if not token.is_punct and not token.is_space]\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, stop_words='english')\n",
        "X = vectorizer.fit_transform(c.values())\n",
        "matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=c.keys())\n",
        "\n",
        "print(matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "objV9rmU7aMT",
        "outputId": "bae7baff-8f29-4af1-ba09-72b8d0d6ad39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                0.00006  1998  aside  ballot  charity  decade  florida  guile  \\\n",
            "Lincoln1865           0     0      0       0        1       0        0      0   \n",
            "TrumpMay26            0     0      0       1        0       0        0      0   \n",
            "Wikipedia             0     1      0       0        0       0        0      0   \n",
            "FortuneMay26          1     0      0       0        0       1        0      0   \n",
            "TheHillApr07          0     0      0       0        0       0        1      0   \n",
            "KingJamesBible        0     0      1       0        0       0        0      1   \n",
            "\n",
            "                lay  mail  malice  oregon  primary  state  total  trump  vote  \\\n",
            "Lincoln1865       0     0       1       0        0      0      0      0     0   \n",
            "TrumpMay26        0     1       0       0        0      0      0      0     0   \n",
            "Wikipedia         0     0       0       1        0      1      0      0     0   \n",
            "FortuneMay26      0     0       0       0        0      0      1      0     0   \n",
            "TheHillApr07      0     1       0       0        1      0      0      1     1   \n",
            "KingJamesBible    1     0       1       0        0      0      0      0     0   \n",
            "\n",
            "                way  wherefore  zero  \n",
            "Lincoln1865       0          0     0  \n",
            "TrumpMay26        1          0     1  \n",
            "Wikipedia         0          0     0  \n",
            "FortuneMay26      0          0     0  \n",
            "TheHillApr07      0          0     0  \n",
            "KingJamesBible    0          1     0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['I', 'far', 'make', 'whereaft'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer, stop_words='english')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(c.values())\n",
        "\n",
        "print(pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=c.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzMi27Ye7b9p",
        "outputId": "958cf751-b375-45a3-9f85-a6f51166b81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                0.00006     1998     aside    ballot   charity   decade  \\\n",
            "Lincoln1865     0.00000  0.00000  0.000000  0.000000  0.773262  0.00000   \n",
            "TrumpMay26      0.00000  0.00000  0.000000  0.521823  0.000000  0.00000   \n",
            "Wikipedia       0.00000  0.57735  0.000000  0.000000  0.000000  0.00000   \n",
            "FortuneMay26    0.57735  0.00000  0.000000  0.000000  0.000000  0.57735   \n",
            "TheHillApr07    0.00000  0.00000  0.000000  0.000000  0.000000  0.00000   \n",
            "KingJamesBible  0.00000  0.00000  0.462625  0.000000  0.000000  0.00000   \n",
            "\n",
            "                 florida     guile       lay      mail    malice   oregon  \\\n",
            "Lincoln1865     0.000000  0.000000  0.000000  0.000000  0.634086  0.00000   \n",
            "TrumpMay26      0.000000  0.000000  0.000000  0.427903  0.000000  0.00000   \n",
            "Wikipedia       0.000000  0.000000  0.000000  0.000000  0.000000  0.57735   \n",
            "FortuneMay26    0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
            "TheHillApr07    0.462625  0.000000  0.000000  0.379359  0.000000  0.00000   \n",
            "KingJamesBible  0.000000  0.462625  0.462625  0.000000  0.379359  0.00000   \n",
            "\n",
            "                 primary    state    total     trump      vote       way  \\\n",
            "Lincoln1865     0.000000  0.00000  0.00000  0.000000  0.000000  0.000000   \n",
            "TrumpMay26      0.000000  0.00000  0.00000  0.000000  0.000000  0.521823   \n",
            "Wikipedia       0.000000  0.57735  0.00000  0.000000  0.000000  0.000000   \n",
            "FortuneMay26    0.000000  0.00000  0.57735  0.000000  0.000000  0.000000   \n",
            "TheHillApr07    0.462625  0.00000  0.00000  0.462625  0.462625  0.000000   \n",
            "KingJamesBible  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000   \n",
            "\n",
            "                wherefore      zero  \n",
            "Lincoln1865      0.000000  0.000000  \n",
            "TrumpMay26       0.000000  0.521823  \n",
            "Wikipedia        0.000000  0.000000  \n",
            "FortuneMay26     0.000000  0.000000  \n",
            "TheHillApr07     0.000000  0.000000  \n",
            "KingJamesBible   0.462625  0.000000  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['I', 'far', 'make', 'whereaft'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZBn5w-F7b_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GpCL68MA7cBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "malice_vector = matrix['malice'].values\n",
        "vote_vector = matrix['vote'].values\n",
        "mail_vector = matrix['mail'].values\n",
        "\n",
        "cosine_malice_vote = cosine_similarity(malice_vector.reshape(1, -1), vote_vector.reshape(1, -1))\n",
        "cosine_mail_vote = cosine_similarity(mail_vector.reshape(1, -1), vote_vector.reshape(1, -1))\n",
        "\n",
        "print(\"Cosine similarity between 'malice' and 'vote':\", cosine_malice_vote[0][0])\n",
        "print(\"Cosine similarity between 'mail' and 'vote':\", cosine_mail_vote[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuYZ1A-27cEK",
        "outputId": "ac1f36bd-507d-4d81-c19b-b1e17eca2c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'malice' and 'vote': 0.0\n",
            "Cosine similarity between 'mail' and 'vote': 0.7071067811865475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r9NT2QXr7cGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B1yv3uZk7cIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "grHRLoQ47cL5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}